# =====================================================
# TP2 ‚Äì IMPLEMENTATION & DEPLOIEMENT DES MODELES ML
# APPLICATION STREAMLIT (VERSION FINALE)
# =====================================================

import streamlit as st
import pandas as pd
import numpy as np
import pickle
import os

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import (
    accuracy_score, confusion_matrix, roc_curve, auc,
    mean_absolute_error, mean_squared_error, r2_score
)

from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor
from sklearn.ensemble import (
    RandomForestClassifier,
    GradientBoostingClassifier,
    RandomForestRegressor
)

# =========================
# CONFIG STREAMLIT
# =========================
st.set_page_config(
    page_title="TP2 - ML & D√©ploiement",
    layout="wide"
)

st.title("üìä TP2 ‚Äì Impl√©mentation & D√©ploiement des Mod√®les ML")
st.write("Licence MTQ ‚Äì Introduction √† l‚ÄôIntelligence Artificielle")


"""  
 [, "Exp√©rimentation ‚Äì Nouveau Dataset" ] : A ete add pour Partie 3
"""
menu = st.sidebar.selectbox(
    "Choisir une partie",
    ["Classification ‚Äì Census Income", "R√©gression ‚Äì Auto MPG","Exp√©rimentation ‚Äì Nouveau Dataset"]
)

# Cr√©er dossier models si inexistant
if not os.path.exists("models"):
    os.makedirs("models")



# ====================================================
# PARTIE 1 : CLASSIFICATION - CENSUS
# =====================================================
if menu == "Classification ‚Äì Census Income":

    st.header("üß† Classification : Census Income")

    st.info("Chargez le fichier census.csv pour entra√Æner le mod√®le")

    uploaded_file = st.file_uploader(
        "üìÇ Charger le fichier census.csv",
        type=["csv"]
    )

    if uploaded_file is None:
        st.warning("Veuillez charger le fichier census.csv pour continuer")
        st.stop()

    data = pd.read_csv(uploaded_file)

    st.subheader("Aper√ßu des donn√©es")
    st.write(data.head())

    # Nettoyage des donn√©es
    data.replace(" ?", np.nan, inplace=True)
    data.dropna(inplace=True)

    X = data.drop("Income", axis=1)
    y = data["Income"]

    # Encodage des variables cat√©gorielles
    X = pd.get_dummies(X)

    # S√©paration train / test
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )

    # Choix du mod√®le
    model_choice = st.selectbox(
        "Choisir un mod√®le",
        ["KNN", "Random Forest", "Gradient Boosting"]
    )

    if model_choice == "KNN":
        k = st.slider("Nombre de voisins (k)", 1, 15, 5)
        model = KNeighborsClassifier(n_neighbors=k)

    elif model_choice == "Random Forest":
        n = st.slider("Nombre d'arbres", 50, 300, 100)
        model = RandomForestClassifier(
            n_estimators=n,
            random_state=42
        )

    else:
        model = GradientBoostingClassifier(random_state=42)

    # Entra√Ænement
    model.fit(X_train, y_train)

    # Pr√©dictions
    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)

    st.success(f"Accuracy du mod√®le : {acc:.4f}")

    # Matrice de confusion
    st.subheader("Matrice de confusion")
    st.write(confusion_matrix(y_test, y_pred))

    # Courbe ROC
    if hasattr(model, "predict_proba"):
        y_score = model.predict_proba(X_test)[:, 1]
        # fpr, tpr, _ = roc_curve(y_test, y_score)
        fpr, tpr, _ = roc_curve(y_test, y_score, pos_label=">50K")

        roc_auc = auc(fpr, tpr)

        st.subheader("Courbe ROC")
        st.line_chart(pd.DataFrame({"FPR": fpr, "TPR": tpr}))
        st.write("AUC :", roc_auc)

    # Sauvegarde du mod√®le
    if st.button("üíæ Sauvegarder le mod√®le (census.pkl)"):
        with open("models/census.pkl", "wb") as f:
            pickle.dump(model, f)
        st.success("Mod√®le census.pkl sauvegard√© avec succ√®s !")

# =====================================================
# PARTIE 2 : REGRESSION - AUTO MPG
# =====================================================
if menu == "R√©gression ‚Äì Auto MPG":

    st.header("üìà R√©gression : Auto MPG")

    st.info("Chargez le fichier auto-mpg.data pour entra√Æner le mod√®le")

    uploaded_file = st.file_uploader(
        "üìÇ Charger le fichier auto-mpg.data",
        type=["data", "txt"]
    )

    if uploaded_file is None:
        st.warning("Veuillez charger le fichier auto-mpg.data pour continuer")
        st.stop()

    columns = [
        "mpg", "cylinders", "displacement", "horsepower",
        "weight", "acceleration", "model_year", "origin", "name"
    ]

    data = pd.read_csv(
        uploaded_file,
        delim_whitespace=True,
        names=columns,
        na_values="?"
    )

    data.dropna(inplace=True)
    data.drop("name", axis=1, inplace=True)

    st.subheader("Aper√ßu des donn√©es")
    st.write(data.head())

    X = data.drop("mpg", axis=1)
    y = data["mpg"]

    # Normalisation
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    # S√©paration train / test
    X_train, X_test, y_train, y_test = train_test_split(
        X_scaled, y, test_size=0.2, random_state=42
    )

    # Choix du mod√®le
    model_choice = st.selectbox(
        "Choisir un mod√®le",
        ["KNN Regressor", "Random Forest Regressor"]
    )

    if model_choice == "KNN Regressor":
        k = st.slider("Nombre de voisins (k)", 1, 15, 5)
        model = KNeighborsRegressor(n_neighbors=k)
    else:
        model = RandomForestRegressor(
            n_estimators=200,
            random_state=42
        )

    # Entra√Ænement
    model.fit(X_train, y_train)

    # Pr√©dictions
    y_pred = model.predict(X_test)

    # √âvaluation
    st.subheader("R√©sultats du mod√®le")
    st.write("MAE :", mean_absolute_error(y_test, y_pred))
    st.write("MSE :", mean_squared_error(y_test, y_pred))
    st.write("R¬≤ :", r2_score(y_test, y_pred))

    # Sauvegarde du mod√®le
    if st.button("üíæ Sauvegarder le mod√®le (auto-mpg.pkl)"):
        with open("models/auto-mpg.pkl", "wb") as f:
            pickle.dump(model, f)
        st.success("Mod√®le auto-mpg.pkl sauvegard√© avec succ√®s !")




# =====================================================
# PARTIE 3 : NOUVEAU -- DATASET (OPTIMIS√âE)
# =====================================================
if menu == "Exp√©rimentation ‚Äì Nouveau Dataset":
    st.header("üÜï Partie 3 : Exp√©rimentation sur un nouveau dataset")
    st.info("Chargez votre fichier (CSV, TXT, XLSX). Si c'est creditcard.csv, cochez 'Classification'.")

    uploaded_file = st.file_uploader("üìÇ Charger votre dataset", type=["csv", "txt", "xlsx"])

    if uploaded_file is None:
        st.warning("Veuillez charger votre dataset pour continuer")
        st.stop()

    # Lecture automatique
    ext = os.path.splitext(uploaded_file.name)[1]
    if ext == ".csv":
        data = pd.read_csv(uploaded_file)
    elif ext in [".txt", ".data"]:
        data = pd.read_csv(uploaded_file, delim_whitespace=True)
    elif ext == ".xlsx":
        data = pd.read_excel(uploaded_file)
    
    st.subheader("Aper√ßu des donn√©es")
    st.write(data.head())

    # S√©lection de la cible
    target_col = st.selectbox("S√©lectionner la colonne cible (target)", data.columns)
    y = data[target_col]
    X = data.drop(target_col, axis=1)

    # --- PR√âTRAITEMENT ---
    # 1. Encodage
    X = pd.get_dummies(X)
    
    # 2. Normalisation (Ajout crucial pour le rapport)
    if st.checkbox("Appliquer la Normalisation (Recommand√©)", value=True):
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        X = pd.DataFrame(X_scaled, columns=X.columns)

    # S√©paration train / test
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Choix de la t√¢che
    task_type = st.radio("Type de t√¢che", ["Classification", "R√©gression"])

    if task_type == "Classification":
        model_choice = st.selectbox("Choisir un mod√®le", ["KNN", "Random Forest", "Gradient Boosting"])
        
        if model_choice == "KNN":
            k = st.slider("Nombre de voisins (k)", 1, 15, 5)
            model = KNeighborsClassifier(n_neighbors=k)
        elif model_choice == "Random Forest":
            n = st.slider("Nombre d'arbres", 50, 300, 100)
            model = RandomForestClassifier(n_estimators=n, random_state=42)
        else:
            model = GradientBoostingClassifier(random_state=42)

        # Entra√Ænement
        if st.button("Lancer l'entra√Ænement"):
            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)
            
            st.success(f"Mod√®le {model_choice} entra√Æn√© avec succ√®s !")
            
            # M√©triques d√©taill√©es (indispensable pour le rapport sur la fraude)
            from sklearn.metrics import classification_report
            col1, col2 = st.columns(2)
            with col1:
                st.metric("Accuracy", f"{accuracy_score(y_test, y_pred):.4f}")
                st.write("**Rapport d√©taill√© :**")
                st.text(classification_report(y_test, y_pred))
            
            with col2:
                st.write("**Matrice de confusion :**")
                st.write(confusion_matrix(y_test, y_pred))

            # Courbe ROC
            if hasattr(model, "predict_proba"):
                y_score = model.predict_proba(X_test)[:, 1]
                # On s'assure que y est binaire pour la courbe ROC
                if len(np.unique(y_test)) == 2:
                    fpr, tpr, _ = roc_curve(y_test, y_score, pos_label=np.unique(y_test)[1])
                    st.subheader("üìà Courbe ROC")
                    st.line_chart(pd.DataFrame({"FPR": fpr, "TPR": tpr}))
                    st.write("AUC :", auc(fpr, tpr))

    else:  # R√©gression
        # ... (Garder ton code de r√©gression ici, il est tr√®s bien)
        model_choice = st.selectbox("Choisir un mod√®le", ["KNN Regressor", "Random Forest Regressor"])
        if model_choice == "KNN Regressor":
            k = st.slider("Nombre de voisins (k)", 1, 15, 5)
            model = KNeighborsRegressor(n_neighbors=k)
        else:
            model = RandomForestRegressor(n_estimators=200, random_state=42)